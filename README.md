# Time-LLM

é‡‘æ²¢å¤§å­¦ICNLã‚µãƒ¼ãƒå‘ã‘ã«æœ€é©åŒ–ã•ã‚ŒãŸ Time-LLM

---

## ğŸ“ æ¦‚è¦

æœ¬ãƒªãƒã‚¸ãƒˆãƒªã¯ä»¥ä¸‹ã®ç’°å¢ƒå‘ã‘ã«äº‹å‰è¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚

- **ç’°å¢ƒ**ï¼šé‡‘æ²¢å¤§å­¦ ICNL ã‚µãƒ¼ãƒ  
- **GPU**ï¼š**2æšã® NVIDIA RTX 5000** ã‚’ä½¿ç”¨  
- **æ··åˆç²¾åº¦**ï¼š**bfloat16 (BF16) ã‚’å¼·åˆ¶**

---

## âš ï¸ æ³¨æ„äº‹é …

1. **PyTorch 2.2.2 ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**  
   ```bash
   conda install pytorch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 pytorch-cuda=12.1 -c pytorch -c nvidia
   ```
2. **Accelerate ã®åˆæœŸè¨­å®š**  
   ä»¥ä¸‹ã®è³ªå•ã«ã¯çŸ¢å°ã‚­ãƒ¼ã§é¸æŠã—ã€Enter ã‚­ãƒ¼ã§ç¢ºå®šã—ã¦ãã ã•ã„ã€‚  
   ç‰¹ã«æœ€å¾Œã®æ··åˆç²¾åº¦ã§ã¯ **`bf16`** ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚

   ```
   In which compute environment are you running?
   â” This machine
     AWS (Amazon SageMaker)

   Which type of machine are you using?
     No distributed training
     multi-CPU
   â” multi-GPU
     TPU
     MPS

   How many different machines will you use (use more than 1 for multi-node training)? [1]: 1

   Do you wish to optimize your script with torch dynamo? [yes/NO]: NO
   Do you want to use DeepSpeed? [yes/NO]: NO
   Do you want to use FullyShardedDataParallel? [yes/NO]: NO
   Do you want to use Megatron-LM? [yes/NO]: NO

   How many GPU(s) should be used for distributed training? [1]: 2
   What GPU(s) (by id) should be used for training on this machine as a comma-separated list? [all]: 0,1

   Do you wish to use FP16 or BF16 (mixed precision)?
     no
     fp16
   â” bf16

   Accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml
   ```

---

## ğŸ“¥ å‚è€ƒ

- GitHub ãƒªãƒã‚¸ãƒˆãƒª:  
  https://github.com/KimMeen/Time-LLM.git

